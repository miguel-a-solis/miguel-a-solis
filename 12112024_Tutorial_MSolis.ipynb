{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**21st IEEE Latin American Robotics Symposium**\n",
        "\n",
        "**Tutorial** - Practical Introduction to Reinforcement Learning with Gym in Python\n",
        "\n",
        "[Dr. Miguel A. Solis](https://www.miguelsolis.info)\n",
        "\n",
        "November 12, 2024"
      ],
      "metadata": {
        "id": "m11IqaNJhMNm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oIjgrO73NTI"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from gym.wrappers.monitoring import video_recorder\n",
        "from IPython.display import HTML\n",
        "from IPython import display\n",
        "import glob\n",
        "import io\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUn1AGj8DKU5"
      },
      "outputs": [],
      "source": [
        "def show_video(env_name):\n",
        "    mp4list = glob.glob('*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = '{}.mp4'.format(env_name)\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display.display(HTML(data='''<video alt=\"test\" autoplay loop controls style=\"height: 400px;\"><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"video could not be found\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test with random actions\n",
        "\n",
        "env_name = \"Taxi-v3\"\n",
        "env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "vid = video_recorder.VideoRecorder(env, path=\"{}.mp4\".format(env_name))\n",
        "state = env.reset()\n",
        "done = False\n",
        "for t in range(100):\n",
        "  vid.capture_frame()\n",
        "  action = env.action_space.sample()\n",
        "  next_state, reward, done, _, _ = env.step(action)\n",
        "  state = next_state\n",
        "  if done:\n",
        "    break\n",
        "vid.close()\n",
        "env.close()\n",
        "\n",
        "show_video(env_name)"
      ],
      "metadata": {
        "id": "YtxAN1NQJPtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cs4jdkeGgWV"
      },
      "outputs": [],
      "source": [
        "# Environment initialization\n",
        "env = gym.make(\"Taxi-v3\", render_mode=\"rgb_array\")\n",
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZGpbo9JIxE_"
      },
      "outputs": [],
      "source": [
        "# Verifying states and actions space\n",
        "print(\"Actions space: {}\".format(env.action_space))\n",
        "print(\"States space: {}\".format(env.observation_space))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YZCsDabQO6S"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "\n",
        "alpha = 0.8\n",
        "gamma = 0.9\n",
        "epsilon = 0.99 # epsilon-greedy\n",
        "max_epsilon = 1\n",
        "min_epsilon = 0.01\n",
        "decay = 0.01\n",
        "\n",
        "training_episodes = 1000\n",
        "max_steps = 100\n",
        "\n",
        "# Q initialization\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxVlfajqrSkw"
      },
      "outputs": [],
      "source": [
        "# Q-learning training\n",
        "\n",
        "training_rewards = []\n",
        "epsilons = []\n",
        "\n",
        "for episode in range(training_episodes):\n",
        "    print(\"====== EPISODE {} ======\".format(episode))\n",
        "    estado, info = env.reset()\n",
        "    total_training_rewards = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        env.render()\n",
        "        p = random.uniform(0, 1)\n",
        "        if p < epsilon:\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            action = np.argmax(Q[state,:])\n",
        "\n",
        "        new_state, reward, end, _, info = env.step(action)\n",
        "        Q[state, action] = Q[state, action] + alpha * (reward + gamma * np.max(Q[new_state, :]) - Q[state, action])\n",
        "        total_training_rewards += reward\n",
        "        state = new_state\n",
        "\n",
        "        if end:\n",
        "            print (\"Episode {} total reward: {}\".format(episode, total_training_rewards))\n",
        "            break\n",
        "\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay*episode)\n",
        "\n",
        "    training_rewards.append(total_training_rewards)\n",
        "    epsilons.append(epsilon)\n",
        "\n",
        "print (\"Training rewards through time: \" + str(sum(training_rewards)/training_episodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJiGUj-3uzBe"
      },
      "outputs": [],
      "source": [
        "# Total rewards evolution through episodes\n",
        "x = range(training_episodes)\n",
        "plt.plot(x, training_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Total training reward per episode')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4uwNlOdvV2d"
      },
      "outputs": [],
      "source": [
        "# Epsilon evolution for epsilon-greedy policy\n",
        "\n",
        "plt.plot(epsilons)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Epsilon')\n",
        "plt.title(\"Epsilon evolution (exploration/explotation)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4Er3VTUvwA-"
      },
      "outputs": [],
      "source": [
        "# Applying the trained agent\n",
        "\n",
        "vid = video_recorder.VideoRecorder(env, path=\"{}.mp4\".format(\"Taxi-v3\"))\n",
        "state, info = env.reset()\n",
        "\n",
        "step = 0\n",
        "fin = False\n",
        "total_rewards = 0\n",
        "\n",
        "for step in range(max_steps):\n",
        "  env.render()\n",
        "  vid.capture_frame()\n",
        "  action = np.argmax(Q[state, :])\n",
        "  new_state, reward, end, _, info = env.step(action)\n",
        "  total_rewards += reward\n",
        "\n",
        "  if fin:\n",
        "    print('Obtained return on episode {}: {}'.format(episode,total_rewards))\n",
        "    break\n",
        "  state = new_state\n",
        "\n",
        "vid.close()\n",
        "env.close()\n",
        "print(\"Total reward for episode:\", total_rewards)\n",
        "\n",
        "show_video('Taxi-v3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}